---
title: 深入GO协程设计原理
date: 2019-08-17 14:26:03
categories: 
- Go
tags:
    - routines
---
Go 有goroutines，这是它能有效开发出并发程序的基础。我们先看看产生goroutines的历史背景，后续我们看看在应用层如何更好地设计routines。
<!-- more -->


## 处理器单元, 线程 和 goroutines
### 处理器单元
起初，计算机在批处理模型中一次运行一个任务。在 60 年代，对更多交互形式的计算的渴望导致了多处理，或分时操作系统的发展。到了 70 年代，这一想法已经在网络服务器、ftp、telnet、rlogin 以及后来 Tim Burners-Lee 的 CERN httpd 上得到了很好的应用，这些服务器通过划分子进程来处理每个传入的网络连接。
在分时系统中，操作系统通过记录当前进程的状态，然后恢复另一个进程的状态，从而在活动进程之间快速切换 CPU，从而保持并发的假象。这称为上下文切换。

#### 上下文切换 
上下文切换有三个主要成本。

1. 内核需要存储该进程的所有 CPU 寄存器的内容，然后恢复另一个进程的值。因为进程切换可以在进程执行的任何位置发生，所以操作系统需要存储所有这些寄存器的内容，因为它不知道当前正在使用哪些寄存器

2. 内核需要将 CPU 的虚拟地址刷新为物理地址映射(TLB 缓存)

3. 操作系统上下文切换的开销，以及选择下一个进程占用 CPU 的调度程序函数的开销。
由于与硬件相关，这些成本相对固定，并且依赖于上下文切换之间所做的工作量来摊销它们的成本-快速上下文切换往往会超过上下文切换之间所做的工作量。

### 线程

这导致线程的被设计开发出来，线程在概念上与进程相同，但共享相同的内存空间。由于线程共享地址空间，所以它们的调度比进程更轻松，因此创建和切换更快。

线程仍然有一个昂贵的上下文切换成本;必须保留许多状态。Goroutines 将线程的概念又向前推进了一步。

### Goroutines
goroutine 不是依赖内核来管理它们之间的调度，而是通过协作的方式调度的。goroutine 之间的切换只发生在预先设计好的时间点，当显式调用 Go 运行时调度程序时。goroutine 被调度器抢占的主要原因包括:

- 在 Channel（Go 特有的语言特性，另一个是 goroutine）上产生阻塞的收发操作。
- Go 语言中 go 这个关键字的使用，虽然不能保证新的 goroutine 会立即被调度。
- 文件操作和网络操作等系统调用。
- 由于进入内存垃圾回收周期而被暂停。

换句话说，goroutine 的调度会在这些时间点发生，在不能得到更多数据，一个 goroutine 无法继续执行时； 或者是在执行环境中，一个 goroutine 需要更多内存空间时。

许多 goroutine 在 Go 运行时被多路复用到一个操作系统线程上。这使得 goroutines 的制造成本和切换成本都很低。在一个进程中有成千上万的 goroutine 是正常的，成百上千的 goroutine 是低于预期的。

从语言的角度来看，调度看起来像一个函数调用，并且具有相同的语义。编译器知道当前正在使用寄存器并自动保存它们。线程调用包含一个特定 goroutine 栈的调度器，这个调度器返回另外一个不同的 goroutine 栈。将此与线程应用程序进行比较，在线程应用程序中，可以在任何时间、任何指令抢占线程。

这导致每个 Go 进程的操作系统线程相对较少，而 Go 的 runtime 负责将一个可运行的 goroutine 分配给一个空闲的操作系统线程。

## 栈的管理
在前一节中，我讨论了 goroutine 如何减少管理(有时是数十万个)过多并发执行线程时的开销。goroutine 还有另一个方面，那就是堆栈管理。

### 进程地址空间
![](/images/go-routines/process.png)
这是一个典型的进程内存布局图。我们感兴趣的关键是堆和栈的位置。

在进程的地址空间中，堆通常位于内存的底部，位于程序代码之上，并向上增长。

堆栈位于虚拟地址空间的顶部，并向下增长。
![](/images/go-routines/guard-page.png)
因为堆和栈相互覆盖将是灾难性的，所以操作系统在堆栈和堆之间安排了一个不可访问的内存区域。

这称为保护页，它有效地限制了进程的栈大小，通常按几兆字节的顺序。



### 线程栈
![](/images/go-routines/threads.png)

线程共享相同的地址空间，因此对于每个线程，它必须有自己的栈和自己的保护页。

由于很难预测特定线程的栈需求，因此必须为每个线程的栈保留大量内存。并寄希望于需求会比这低，同时作为警戒的保护页永远不会被触发。

缺点是，随着程序中线程数量的增加，可用地址空间的数量会减少。
### 管理 Goroutine 的栈
早期的进程模型允许程序员查看堆和栈，一边观察其是否足够大，而不必为此担心。缺点是复杂而昂贵的子进程模型。

线程稍微改善了这种情况，但要求程序员猜测最合适的栈大小;太小，程序将中止;太大，虚拟地址空间将耗尽。

我们已经看到，Go 运行时将大量 goroutine 调度到少量线程上，但是这些 goroutine 的栈需求如何呢?

Goroutine 栈的增长过程
![](/images/go-routines/stack-growth.png)

每个 goroutine 都从堆中分配的一个小尺寸的栈开始。大小随时间而变化，但在 Go 1.5 中，每一个 goroutine 都以 2k 的分配开始栈。

Go 编译器不使用保护页，而是在每个函数调用中插入一个检查，以测试是否有足够的栈空间供函数运行。如果有足够的栈空间，函数将正常运行。（在函数的汇编代码前面，由编译器插入一段检查代码。这个动作可以在函数定义前配置编译器指令，禁用掉，不过要非常非常谨慎地使用）

如果空间不足，Go 进程的 runtime 将在堆上分配一个更大的栈空间，将当前栈的内容复制到新的栈空间，释放旧的栈空间，然后重新启动函数调用。

由于这种检查，goroutine 的初始堆栈可以变得更小，这反过来又允许 Go 程序员将 goroutine 视为廉价的资源。如果有足够多的部分未被使用，Goroutine 栈也会收缩。这是在垃圾回收期间处理的。

## 集成的 network poller

### Go 对 c10k 问题给出的解决方案
在 Go 中，系统调用通常是阻塞操作，这包括读取和写入文件描述符。Go 的 runtime 调度器通过找到一个空闲线程或生成另一个线程来处理这个问题，以便在原始线程阻塞时继续为 goroutines 提供服务。实际上，这对于文件 IO 很有效，因为少量阻塞线程可以快速耗尽本地 IO 带宽。

但是对于网络套接字，按照设计，任何时候几乎所有的 goroutine 都将被阻塞，等待网络 IO。在一个简单的实现中，这将需要和 goroutine 一样多的线程，所有线程都被阻塞，等待网络流量。由于 runtime 和 net 包之间的协作，集成到 Go 的 runtime 中的 network poller 可以有效地处理这个问题。

在较早版本的 Go 中，network poller 是一个 goroutine，`负责使用 kqueue 或 epoll 轮询准备就绪通知`。轮询 goroutine 将通过 channel 与等待的 goroutine 通信。这实现了避免每个线程都做操作系统调用产生的瓶颈，而使用了通过 channel 发送消息这种通用唤醒机制。这意味着调度器不需要关心唤醒源，不需要把唤醒操作看的比较重要。

在 Go 的当前版本中，network poller 已经集成到 runtime 本身中。当 runtime 知道哪个 goroutine 正在等待网络套接字就绪时，它可以在数据包到达时立即将 goroutine 放回相同的 CPU 上，从而减少延迟并增加吞吐量。

### Goroutines, 栈管理和被集成了的 network poller
总之，goroutines 提供了一个强大的抽象，使程序员不必担心线程池或事件循环。goroutine 的栈已经足够大，而不需要考虑线程栈或线程池的大小。被集成了的 network poller 允许程序员避免了复杂的回调风格代码，同时仍然利用操作系统中可用的最有效的 IO 完成逻辑。runtime 确保有足够的线程来服务所有 goroutine 并保持 CPU 核处于活动状态。所有这些特性对 Go 程序员来说都是透明的。

参考链接
[https://dave.cheney.net/2015/08/08/performance-without-the-event-loop](https://dave.cheney.net/2015/08/08/performance-without-the-event-loop)
